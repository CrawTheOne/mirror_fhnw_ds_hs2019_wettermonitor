{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse und Wahrscheinlichkeitsrechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\simon\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\simon\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\.libs\\libopenblas.2V74HQ3MKNZHDCKJELIPPY7V6QMK3UOZ.gfortran-win32.dll\n",
      "c:\\users\\simon\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\.libs\\libopenblas.FN5FF57TWHUYLRG54LA6B33EZPHYZZL4.gfortran-win32.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:8086\n"
     ]
    }
   ],
   "source": [
    "import config as cfg\n",
    "import Import_Data_API as ImpData\n",
    "\n",
    "import pandas as pd\n",
    "from influxdb import DataFrameClient, InfluxDBClient\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from fhnw_ds_hs2019_weatherstation_api import data_import as weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cfg.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowindex_as_col(df):\n",
    "    \"\"\"add row index(time) to new column. df = dataframe, name_col = new column name\"\"\"\n",
    "    df.index.name = \"Time\"\n",
    "    df = df.reset_index(inplace=False)\n",
    "    df = pd.DataFrame(df)\n",
    "    return df\n",
    "\n",
    "def appropriate_dtypes(df, column_name, result_dtype ):\n",
    "    \"\"\"Datentypen ändern\"\"\"\n",
    "    df = df.astype({column_name: result_dtype})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sind Daten von Mythenquai und Tiefenbrunnen unterschiedlich?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = ImpData.select_timedelta(0,7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.equals(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.corrwith(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Daten ausser den Winddaten sehen sich ziemlich ähnlich. Es wäre somit sinnvoll die Winddaten für beide Stationen grafisch für die Segler darzustellen. Alle die anderen Daten mit einer Korrelation von über 90% können von einer Station übernommen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Data from InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mythenquai_, tiefenbrunnen_ = ImpData.select_timedelta(0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mythenquai_ = appropriate_dtypes(mythenquai_, \"humidity\" , np.int8)\n",
    "tiefenbrunnen_ = appropriate_dtypes(tiefenbrunnen_, \"wind_direction\", np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mythenquai_ = appropriate_dtypes(mythenquai_, \"humidity\", np.int8)\n",
    "mythenquai_ = appropriate_dtypes(mythenquai_,\"wind_direction\", np.int16 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aesthetische Einstellungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(tiefenbrunnen_.describe(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "round(mythenquai_.describe(),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korrelationen Bereich Temperatur und Feuchte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiefenbrunnen_adapt_temp = tiefenbrunnen_.drop( columns = [\"wind_direction\",\"wind_force_avg_10min\",\n",
    "                                                             \"wind_gust_max_10min\",\"wind_speed_avg_10min\",\n",
    "                                                             \"windchill\", \"barometric_pressure_qfe\"])\n",
    "tiefenbrunnen_adapt_temp = rowindex_as_col(tiefenbrunnen_adapt_temp)\n",
    "tiefenbrunnen_adapt_temp.head()\n",
    "sns.pairplot(tiefenbrunnen_adapt_temp, kind = \"reg\", diag_kind = \"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auffälligkeiten:\n",
    "- Starke Negative Korrelation zwischen Luftfeuchte und Temperatur\n",
    "- Eigentlich sollte der Taupunkt bei 100% relativer Luftfeuchte sein. Erklärung?\n",
    "- Es bestehen positive Korrelationen zwischen Lufttemperatur, Wassertemperatur und Taupunkt.\n",
    "- Negative Korrelationen zwischen Lufttemperatur und Luftfeuchtigkeit.\n",
    "\n",
    "#### Bemerkungen\n",
    "- Barometrischer Druck entfernt, da schwache Korrelationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korrelationen Bereich Wind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiefenbrunnen_adapt_wind = tiefenbrunnen_.drop( columns = [\"air_temperature\",\"barometric_pressure_qfe\",\"dew_point\",\n",
    "                                                             \"humidity\", \"water_temperature\", \"windchill\"])\n",
    "sns.pairplot(tiefenbrunnen_adapt_wind, kind = \"reg\", diag_kind = \"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auffällligkeiten:\n",
    "- Positive Korrelation zwischen Windrichtung, Geschwindigkeiten und WIndstärke\n",
    "- Starke Positive Korrelation zwischen Windgeschwindigkeit, Stärke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prognose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Referenz werden die Temperaturdaten aus dem Jahr 2018 genommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2_file = \"../influxdb-1.7.8-1/data/messwerte_mythenquai_2007-2018.csv\"\n",
    "df_prediction = pd.read_csv(path_2_file, index_col=0)\n",
    "#df_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_prediction\n",
    "df_pred.index = pd.to_datetime(df_pred.index)\n",
    "\n",
    "df_pred = df_pred.loc[\"2018-01-01\":\"2018-12-31\"]\n",
    "\n",
    "len(df_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verfahren mit Kolmogorov-Smirnoff Test:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werden Daten von zwei Jahren in zwei Tage gruppiert. Die gruppierten Daten werden dann mit\n",
    "dem aktuellen \"ganzen\" Tag verglichen und geben dann die Temperatur für den nachfolgenden Tag aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_in_grouped_days(df, column, group_string, group_int):\n",
    "    \"\"\" \n",
    "    Splits distributions in separate lists of days together as new list of values. This DF is always used as reference to determine temperature of next day.\n",
    "    Input: df = vector or dataframe, column = specific column index, group_string = \"3D\", \"D\", group_int = integer days want to group\n",
    "    \"\"\" \n",
    "    \n",
    "    df.index = pd.to_datetime(df.index) ## Index conversion to datetime\n",
    "    day_shift = -1\n",
    "\n",
    "    df1 = df.iloc[:, column]\n",
    "    \n",
    "    grouped_df = df1.resample(group_string).aggregate(lambda tdf: tdf.tolist()) #Creates new df by grouping days\n",
    "    grouped_df = pd.DataFrame(grouped_df)\n",
    "    \n",
    "    df2 = df.iloc[:, column]\n",
    "    \n",
    "    grouped_df_max = df2.resample(\"D\").aggregate(lambda tdf: tdf.max())\n",
    "    grouped_df_max = pd.DataFrame(grouped_df_max)\n",
    "    grouped_df_max = grouped_df_max[::group_int].iloc[1:] ## takes each third row and drops the first one\n",
    "\n",
    "    new_df = pd.concat([grouped_df, grouped_df_max], axis = 1)\n",
    "    new_df = new_df.shift(day_shift).dropna() \n",
    "    new_df.columns = [\"grouped_values\", \"Temp_next_day\"]\n",
    "    \n",
    "    return new_df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = get_values_in_grouped_days(df_pred, 0, \"1D\", 1)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_max = df_prediction.loc[\"2010-08-02\":\"2018-08-02\"].max()\n",
    "\n",
    "df_test = df_prediction.loc[\"2010-01-01\":\"2017-12-31\"]\n",
    "df_test = df_test.iloc[:,0]\n",
    "df_test = pd.DataFrame(df_test)\n",
    "\n",
    "df_test2 = df_prediction.loc[\"2018-01-11\":\"2018-01-12\"]\n",
    "\n",
    "#df_test = df_test.reset_index(drop = True)\n",
    "#df_test.head()\n",
    "#df_test2\n",
    "#df_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorhersage mit KS-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats as spstats\n",
    "\n",
    "def prediction_ks_test(df_for_test, sample_df):\n",
    "    \"\"\"Predicts the value of next day by using the statistical KS-Test of Scipy package. It's used to compare the distributions of two\n",
    "    test samples. The higher the probability value the better is the fit.\n",
    "    Input: df_for_test: dataframe of one day to perform the test / sample_df: specific sample df as reference\n",
    "    Returns: fitting maximum temperature of next day\n",
    "    \"\"\"\n",
    "    KS_p_val_to_compare = 0\n",
    "    fitting_temp_next_day = 0\n",
    "    iterations = 0 ## length not equal of sample df \n",
    "        \n",
    "    for row in range(0, len(sample_df)):\n",
    "                                \n",
    "        KS_stat, KS_p_val = spstats.ks_2samp(df_for_test.iloc[:, 0], sample_df.iloc[row, 0]) # Perform t-test\n",
    "          \n",
    "        if KS_p_val > KS_p_val_to_compare:\n",
    "            KS_p_val_to_compare = KS_p_val\n",
    "            fitting_temp_next_day = sample_df.iloc[row, 1]\n",
    "            \n",
    "        iterations = iterations + 1        \n",
    "            \n",
    "    #print(\"P-Wert: {} / Iterations: {} / Fitting Temp.: {}\".format(KS_p_val_to_compare, iterations, fitting_temp_next_day))                                                                                                                            \n",
    "    \n",
    "    return fitting_temp_next_day\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Kolmogorov-Smirnoff:\n",
    "Der Durchschnitt aller Messwerte aus einem Jahr.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_test_KS(df_test, sample_df, days_used_for_prediction):\n",
    "    \"\"\"Purpose is to test a generated prediction method of one year. Calculates the average deviation of one simulative test year\n",
    "    Parameters: df_test = df which should be tested(first column) / days_used_... = 1d (how much days're used for the prediction)\n",
    "    \"\"\"\n",
    "    days_offset = days_used_for_prediction         \n",
    "    start_date_str = \"2015-01-01\" ## Check all Values for this year\n",
    "    start_date = datetime.datetime.strptime(start_date_str,  \"%Y-%m-%d\")\n",
    "    days_in_df_test = len(df_test.index.dayofyear.unique())\n",
    "    \n",
    "    test_results = np.array([])\n",
    "    \n",
    "    for day in range(days_used_for_prediction, days_in_df_test):\n",
    "        ## Maximum Temperature of +1day or how much \n",
    "        time_delta1,time_delta2 = datetime.timedelta(days = day), datetime.timedelta(days = day + 1)\n",
    "        val_date1, val_date2 = start_date + time_delta1, start_date + time_delta2      ## Valuable date\n",
    "         \n",
    "        df_ref = df_test.loc[val_date1:val_date2]\n",
    "        ## df_max = df_ref.values.max()\n",
    "        if df_ref.empty == False:\n",
    "            df_max = np.max(df_ref)\n",
    "        \n",
    "        ###### Function part: KS_test \n",
    "        KS_time_delta = datetime.timedelta(days = day - days_used_for_prediction) ## time-frame for prediction\n",
    "        KS_val_date1, KS_val_date2 = start_date + KS_time_delta, start_date + time_delta1 ## same as ttest_timedelta +1\n",
    "        KS_df_test = df_test.loc[KS_val_date1 : KS_val_date2]\n",
    "        \n",
    "        if KS_df_test.empty == False:\n",
    "            KS_test_temp = prediction_ks_test(KS_df_test, sample_df)\n",
    "        \n",
    "        deviation_test = abs(df_max - KS_test_temp) ## Absolute difference to real value\n",
    "        \n",
    "        test_results = np.append(test_results, deviation_test)\n",
    "            \n",
    "    test_result = np.mean(test_results)\n",
    "        \n",
    "    print(\"The average deviation of a year: {} K\".format(test_result))\n",
    "\n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_results = prediction_test_KS(df_test, sample_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_results))\n",
    "sns.distplot(test_results, kde = False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
